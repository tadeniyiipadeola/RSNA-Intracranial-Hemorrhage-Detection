{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/qubvel/classification_models.git\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport cv2\nimport tensorflow as tf\n\nfrom math import ceil, floor\nfrom copy import deepcopy\nfrom tqdm.notebook import tqdm\nfrom imgaug import augmenters as iaa\n\nimport tensorflow.keras as keras\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import AUC, Recall, Precision, BinaryCrossentropy\nfrom classification_models.tfkeras import Classifiers\nfrom tensorflow.keras.layers import *\nfrom sklearn.utils.class_weight import compute_class_weight\n\ndef calculating_class_weights(y_true):\n    number_dim = np.shape(y_true)[1]\n    weights = np.empty([number_dim, 2])\n    for i in range(number_dim):\n        weights[i] = compute_class_weight('balanced', np.unique(y_true[:, i]), y_true[:, i])\n    return weights\n\ndef _read(path, SHAPE):\n    img = cv2.imread('../input/rsna-cq500-abnormal-data/'+path)\n    img = cv2.resize(img, dsize=(256, 256))\n    return img/255.0\n\n# Image Augmentation\nsometimes = lambda aug: iaa.Sometimes(0.25, aug)\naugmentation = iaa.Sequential([ iaa.Fliplr(0.25),\n                                iaa.Flipud(0.10),\n                                sometimes(iaa.Crop(px=(0, 25), keep_size = True, sample_independently = False))   \n                            ], random_order = True)       \n        \n# Generators\nclass TrainDataGenerator(keras.utils.Sequence):\n    def __init__(self, dataset, class_names, batch_size = 16, img_size = (256, 256, 3), \n                 augment = False, shuffle = True, *args, **kwargs):\n        self.dataset = dataset\n        self.ids = self.dataset['imgfile'].values\n        self.labels = self.dataset[class_names].values\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.augment = augment\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(ceil(len(self.ids) / self.batch_size))\n\n    def __getitem__(self, index):\n        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n        X, Y = self.__data_generation(indices)\n        return X, Y\n\n    def augmentor(self, image):\n        augment_img = augmentation        \n        image_aug = augment_img.augment_image(image)\n        return image_aug\n\n    def on_epoch_end(self):\n        self.indices = np.arange(len(self.ids))\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n\n    def __data_generation(self, indices):\n        X = np.empty((self.batch_size, *self.img_size))\n        Y = np.empty((self.batch_size, len(class_names)), dtype=np.float32)\n        \n        for i, index in enumerate(indices):\n            ID = self.ids[index]\n            image = _read(ID, self.img_size)\n            if self.augment:\n                X[i,] = self.augmentor(image)\n            else:\n                X[i,] = image\n            Y[i,] = self.labels[index]        \n        return X, Y\n\ndef ModelCheckpointFull(model_name):\n    return ModelCheckpoint(model_name, \n                            monitor = 'val_loss', \n                            verbose = 1, \n                            save_best_only = True, \n                            save_weights_only = True, \n                            mode = 'min', \n                            period = 1)\n\n# Create Model\ndef create_model(num_classes):\n    K.clear_session()\n    \n#     SE_resnext101, preprocess_input = Classifiers.get('seresnext101')\n#     engine = SE_resnext101(include_top=False,\n#                            input_shape=(256, 256, 3),\n#                            backend = tf.keras.backend,\n#                            layers = tf.keras.layers,\n#                            models = tf.keras.models,\n#                            utils = tf.keras.utils,\n#                           weights = 'imagenet')\n## mobileNet\n    mobileNet, preprocess_input = Classifiers.get('mobilenet')\n    engine = mobileNet(include_top=False,\n                           input_shape=(256, 256, 3),\n                           backend = tf.keras.backend,\n                           layers = tf.keras.layers,\n                           models = tf.keras.models,\n                           utils = tf.keras.utils,\n                          weights = 'imagenet')\n\n##\n\n    x = GlobalAveragePooling2D(name='avg_pool')(engine.output)\n    x = Dropout(0.15)(x)\n    out = Dense(num_classes, activation='sigmoid', name='new_output')(x)\n    model = Model(inputs=engine.input, outputs=out)\n\n    return model\n\ndef metrics_define(num_classes):\n    metrics_all = ['accuracy',\n    AUC(curve='PR',multi_label=True,name='auc_pr'),\n    AUC(multi_label=True, name='auc_roc'),\n    Recall(),\n    Precision(),\n    BinaryCrossentropy(name='bi_crent')\n    ]\n\n    return metrics_all\n\ndef get_weighted_loss(weights):\n    def weighted_loss(y_true, y_pred):\n        return K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*K.binary_crossentropy(y_true, y_pred), axis=-1)\n    return weighted_loss\n\nfrom prettytable import PrettyTable\nfrom sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom sklearn.metrics import multilabel_confusion_matrix\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport seaborn as sns\n\n\ndef print_metrics_table(y_true, y_hat, y_pred, class_names):\n    myTable = PrettyTable([\"Class Name\", \"ROC_AUC\", \"Precsion\", \"Recall\", \"F1_Score\", \"Accuracy\"])\n\n    for i in range(len(class_names)) :\n        \n        myTable.add_row([class_names[i], \"%.4f\" % roc_auc_score(y_true[:, i], y_hat[:, i]),\n                        \"%.4f\" % precision_score(y_true[:, i], y_pred[:, i]), \"%.4f\" % recall_score(y_true[:, i], y_pred[:, i]),\n                        \"%.4f\" % f1_score(y_true[:, i], y_pred[:, i]), \"%.4f\" % accuracy_score(y_true[:, i], y_pred[:, i])\n                        ])\n\n    myTable.add_row(['Average', \"%.4f\" % roc_auc_score(y_true, y_hat),\n                    \"%.4f\" % precision_score(y_true, y_pred, average='macro'), \"%.4f\" % recall_score(y_true, y_pred, average='macro'),\n                    \"%.4f\" % f1_score(y_true, y_pred, average='macro'), \"%.4f\" % accuracy_score(y_true, y_pred)\n                    ])\n    print(myTable)\n\ndef print_precision_recall_curves(y_true, y_hat, y_pred, class_names):\n        # For each class\n    precision = dict()\n    recall = dict()\n    average_precision = dict()\n    for i in range(len(class_names)):\n        precision[i], recall[i], _ = precision_recall_curve(y_true[:, i],\n                                                            y_hat[:, i])\n        average_precision[i] = average_precision_score(y_true[:, i], y_hat[:, i])\n\n    # A \"micro-average\": quantifying score on all classes jointly\n    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_true.ravel(),\n        y_hat.ravel())\n    average_precision[\"micro\"] = average_precision_score(y_true, y_hat,\n                                                        average=\"micro\")\n    print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n        .format(average_precision[\"micro\"]))\n    plt.figure()\n    plt.step(recall['micro'], precision['micro'], where='post')\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.ylim([0.0, 1.05])\n    plt.xlim([0.0, 1.0])\n    plt.title(\n        'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n        .format(average_precision[\"micro\"]))\n    plt.show()\n    for i in range(len(class_names)):\n        plt.figure()\n        plt.plot(recall[i], precision[i], label='Precision-recall for class {0} (area = {1:0.2f})'.format(i, average_precision[i]))\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('Recall')\n        plt.ylabel('Precision')\n        plt.title('Precision-Recall Curve for Class {}'.format(class_names[i]))\n        plt.legend(loc=\"lower right\")\n        plt.show()\n\ndef print_auc_curves(y_true, y_hat, y_pred, class_names):\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    roc_auc_sc = dict()\n    for i in range(len(class_names)):\n        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_hat[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n        roc_auc_sc[i] = roc_auc_score(y_true[:, i], y_hat[:, i])\n\n    # Compute micro-average ROC curve and ROC area\n    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_hat.ravel())\n    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n    for i in range(len(class_names)):\n        plt.figure()\n        plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Receiver operating characteristic for class {}'.format(class_names[i]))\n        plt.legend(loc=\"lower right\")\n        plt.show()\n\ndef print_confusion_matrix(y_true, y_hat, y_pred, class_names):\n    print(multilabel_confusion_matrix(y_true, y_pred))\n\ndef print_on_vs_all_cmatrix(y_true, y_hat, y_pred, class_names):\n    confusion = multilabel_confusion_matrix(y_true, y_pred)\n\n    # Plot confusion matrix \n    fig = plt.figure(figsize = (14, 8))\n    for i, (label, matrix) in enumerate(zip(class_names[0:6], confusion[0:6])):\n        plt.subplot(f'23{i+1}')\n        labels = [f'not_{label}', label]\n        cm = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n        sns.heatmap(cm, annot = True, square = True, cbar = False, cmap = 'Blues', \n                    xticklabels = labels, yticklabels = labels, linecolor = 'black', linewidth = 1)\n        plt.title(labels[0])\n\n    plt.tight_layout()\n    plt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-15T00:45:28.234063Z","iopub.execute_input":"2021-11-15T00:45:28.234462Z","iopub.status.idle":"2021-11-15T00:45:52.640244Z","shell.execute_reply.started":"2021-11-15T00:45:28.234341Z","shell.execute_reply":"2021-11-15T00:45:52.639192Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/kfold-splits-rsna-cq500/Train_f5.csv')\nval_df = pd.read_csv('../input/kfold-splits-rsna-cq500/Validation_f5.csv')\n\nHEIGHT = 256\nWIDTH = 256\nCHANNELS = 3\nTRAIN_BATCH_SIZE = 32\nVALID_BATCH_SIZE = 64\nSHAPE = (HEIGHT, WIDTH, CHANNELS)\n\nclass_names = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n\nweights = calculating_class_weights((train_df[class_names].values).astype(np.float32))\nprint(weights)\n\ndata_generator_train = TrainDataGenerator(train_df,\n                                          class_names,\n                                          TRAIN_BATCH_SIZE,\n                                          SHAPE,\n                                          augment = True,\n                                          shuffle = True)\ndata_generator_val = TrainDataGenerator(val_df,\n                                        class_names, \n                                        VALID_BATCH_SIZE, \n                                        SHAPE,\n                                        augment = False,\n                                        shuffle = True\n                                        )\n\nTRAIN_STEPS = int(len(data_generator_train)/2)\nprint(TRAIN_STEPS)\nVal_STEPS = int(len(data_generator_val)/2)\nprint(Val_STEPS)\nLR = 5e-5","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:46:29.045624Z","iopub.execute_input":"2021-11-15T00:46:29.045938Z","iopub.status.idle":"2021-11-15T00:46:29.493527Z","shell.execute_reply.started":"2021-11-15T00:46:29.045891Z","shell.execute_reply":"2021-11-15T00:46:29.491391Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:46:54.560234Z","iopub.execute_input":"2021-11-15T00:46:54.560539Z","iopub.status.idle":"2021-11-15T00:46:54.589945Z","shell.execute_reply.started":"2021-11-15T00:46:54.560508Z","shell.execute_reply":"2021-11-15T00:46:54.588872Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"Metrics = metrics_define(len(class_names))\n\nmodel = create_model(len(class_names))\n# model.load_weights('../input/rsna-cq500-abnormal-weight/model.h5')\nmodel.compile(optimizer = Adam(learning_rate = LR),\n              loss = get_weighted_loss(weights),\n              metrics = Metrics)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:47:01.266798Z","iopub.execute_input":"2021-11-15T00:47:01.267116Z","iopub.status.idle":"2021-11-15T00:47:06.833528Z","shell.execute_reply.started":"2021-11-15T00:47:01.267077Z","shell.execute_reply":"2021-11-15T00:47:06.832526Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"history = model.fit(data_generator_train,\n                    validation_data = data_generator_val,\n                    validation_steps = Val_STEPS,\n                    steps_per_epoch = TRAIN_STEPS,\n                    epochs = 15,\n                    callbacks = [ModelCheckpointFull('mobileNet_fold5.h5')],\n                    verbose = 1, workers=4\n                    )","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:47:24.142280Z","iopub.execute_input":"2021-11-15T00:47:24.142603Z","iopub.status.idle":"2021-11-15T02:33:04.473130Z","shell.execute_reply.started":"2021-11-15T00:47:24.142557Z","shell.execute_reply":"2021-11-15T02:33:04.471979Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:34:47.562841Z","iopub.execute_input":"2021-11-15T02:34:47.563202Z","iopub.status.idle":"2021-11-15T02:34:47.867201Z","shell.execute_reply.started":"2021-11-15T02:34:47.563165Z","shell.execute_reply":"2021-11-15T02:34:47.866208Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['auc_pr'])\nplt.plot(history.history['val_auc_pr'])\nplt.title('model auc_precision')\nplt.ylabel('auc_pr')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:36:35.069880Z","iopub.execute_input":"2021-11-15T02:36:35.070747Z","iopub.status.idle":"2021-11-15T02:36:35.341253Z","shell.execute_reply.started":"2021-11-15T02:36:35.070710Z","shell.execute_reply":"2021-11-15T02:36:35.339407Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = create_model(5)\nmodel.load_weights('mobileNet_fold5.h5')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:36:50.413726Z","iopub.execute_input":"2021-11-15T02:36:50.414300Z","iopub.status.idle":"2021-11-15T02:36:51.326643Z","shell.execute_reply.started":"2021-11-15T02:36:50.414263Z","shell.execute_reply":"2021-11-15T02:36:51.325649Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"val_df = pd.read_csv('../input/kfold-splits-rsna-cq500/Validation_f5.csv')\nprint(len(val_df))\n\nHEIGHT = 256\nWIDTH = 256\nCHANNELS = 3\nVALID_BATCH_SIZE = 64\nSHAPE = (HEIGHT, WIDTH, CHANNELS)\n\nclass_names = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\ndata_generator_test = TrainDataGenerator(val_df,\n                                        class_names, \n                                        VALID_BATCH_SIZE, \n                                        SHAPE,\n                                        augment = False,\n                                        shuffle = False\n                                        )\n\ny_true = val_df[class_names].values\ny_hat = model.predict(data_generator_test, verbose=1)\n\ny_hat = y_hat[0:len(y_true)]\ny_pred = np.round(y_hat)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:36:53.792390Z","iopub.execute_input":"2021-11-15T02:36:53.793277Z","iopub.status.idle":"2021-11-15T02:39:11.818964Z","shell.execute_reply.started":"2021-11-15T02:36:53.793223Z","shell.execute_reply":"2021-11-15T02:39:11.817873Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print_metrics_table(y_true, y_hat, y_pred, class_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:39:20.010514Z","iopub.execute_input":"2021-11-15T02:39:20.010830Z","iopub.status.idle":"2021-11-15T02:39:20.382018Z","shell.execute_reply.started":"2021-11-15T02:39:20.010797Z","shell.execute_reply":"2021-11-15T02:39:20.380764Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print_precision_recall_curves(y_true, y_hat, y_pred, class_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:39:32.624311Z","iopub.execute_input":"2021-11-15T02:39:32.624660Z","iopub.status.idle":"2021-11-15T02:39:34.527362Z","shell.execute_reply.started":"2021-11-15T02:39:32.624625Z","shell.execute_reply":"2021-11-15T02:39:34.526025Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print_auc_curves(y_true, y_hat, y_pred, class_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:39:46.492663Z","iopub.execute_input":"2021-11-15T02:39:46.492984Z","iopub.status.idle":"2021-11-15T02:39:47.792990Z","shell.execute_reply.started":"2021-11-15T02:39:46.492936Z","shell.execute_reply":"2021-11-15T02:39:47.791985Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print_confusion_matrix(y_true, y_hat, y_pred, class_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:40:02.675663Z","iopub.execute_input":"2021-11-15T02:40:02.676765Z","iopub.status.idle":"2021-11-15T02:40:02.699990Z","shell.execute_reply.started":"2021-11-15T02:40:02.676716Z","shell.execute_reply":"2021-11-15T02:40:02.698743Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print_on_vs_all_cmatrix(y_true, y_hat, y_pred, class_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:40:17.494566Z","iopub.execute_input":"2021-11-15T02:40:17.494899Z","iopub.status.idle":"2021-11-15T02:40:18.559990Z","shell.execute_reply.started":"2021-11-15T02:40:17.494865Z","shell.execute_reply":"2021-11-15T02:40:18.559111Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"val_df = pd.read_csv('../input/kfold-splits-rsna-cq500/CQ500_Validation_f4.csv')\nprint(len(val_df))\n\nHEIGHT = 256\nWIDTH = 256\nCHANNELS = 3\nVALID_BATCH_SIZE = 64\nSHAPE = (HEIGHT, WIDTH, CHANNELS)\n\nclass_names = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\ndata_generator_test = TrainDataGenerator(val_df,\n                                        class_names, \n                                        VALID_BATCH_SIZE, \n                                        SHAPE,\n                                        augment = False,\n                                        shuffle = False\n                                        )\n\n\ny_true = val_df[class_names].values\ny_hat = model.predict(data_generator_test, verbose=1)\n\ny_hat = y_hat[0:len(y_true)]\ny_pred = np.round(y_hat)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:40:31.357120Z","iopub.execute_input":"2021-11-15T02:40:31.357606Z","iopub.status.idle":"2021-11-15T02:40:50.945591Z","shell.execute_reply.started":"2021-11-15T02:40:31.357565Z","shell.execute_reply":"2021-11-15T02:40:50.944426Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print_metrics_table(y_true, y_hat, y_pred, class_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:41:08.542680Z","iopub.execute_input":"2021-11-15T02:41:08.542998Z","iopub.status.idle":"2021-11-15T02:41:08.637728Z","shell.execute_reply.started":"2021-11-15T02:41:08.542957Z","shell.execute_reply":"2021-11-15T02:41:08.636714Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print_precision_recall_curves(y_true, y_hat, y_pred, class_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:41:23.410300Z","iopub.execute_input":"2021-11-15T02:41:23.410626Z","iopub.status.idle":"2021-11-15T02:41:24.843938Z","shell.execute_reply.started":"2021-11-15T02:41:23.410583Z","shell.execute_reply":"2021-11-15T02:41:24.842911Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print_auc_curves(y_true, y_hat, y_pred, class_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:41:31.417648Z","iopub.execute_input":"2021-11-15T02:41:31.418199Z","iopub.status.idle":"2021-11-15T02:41:32.650084Z","shell.execute_reply.started":"2021-11-15T02:41:31.418163Z","shell.execute_reply":"2021-11-15T02:41:32.649025Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print_confusion_matrix(y_true, y_hat, y_pred, class_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:41:37.282270Z","iopub.execute_input":"2021-11-15T02:41:37.282569Z","iopub.status.idle":"2021-11-15T02:41:37.296227Z","shell.execute_reply.started":"2021-11-15T02:41:37.282536Z","shell.execute_reply":"2021-11-15T02:41:37.295083Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print_on_vs_all_cmatrix(y_true, y_hat, y_pred, class_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:41:46.259439Z","iopub.execute_input":"2021-11-15T02:41:46.259818Z","iopub.status.idle":"2021-11-15T02:41:47.112385Z","shell.execute_reply.started":"2021-11-15T02:41:46.259775Z","shell.execute_reply":"2021-11-15T02:41:47.111103Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"val_df = pd.read_csv('../input/kfold-splits-rsna-cq500/RSNA_Validation_f4.csv')\nprint(len(val_df))\n\nHEIGHT = 256\nWIDTH = 256\nCHANNELS = 3\nVALID_BATCH_SIZE = 64\nSHAPE = (HEIGHT, WIDTH, CHANNELS)\n\nclass_names = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\ndata_generator_test = TrainDataGenerator(val_df,\n                                        class_names, \n                                        VALID_BATCH_SIZE, \n                                        SHAPE,\n                                        augment = False,\n                                        shuffle = False\n                                        )\n\n\ny_true = val_df[class_names].values\ny_hat = model.predict(data_generator_test, verbose=1)\n\ny_hat = y_hat[0:len(y_true)]\ny_pred = np.round(y_hat)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:41:52.366982Z","iopub.execute_input":"2021-11-15T02:41:52.367837Z","iopub.status.idle":"2021-11-15T02:43:49.485431Z","shell.execute_reply.started":"2021-11-15T02:41:52.367792Z","shell.execute_reply":"2021-11-15T02:43:49.484325Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print_metrics_table(y_true, y_hat, y_pred, class_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:44:19.319890Z","iopub.execute_input":"2021-11-15T02:44:19.320571Z","iopub.status.idle":"2021-11-15T02:44:19.633431Z","shell.execute_reply.started":"2021-11-15T02:44:19.320534Z","shell.execute_reply":"2021-11-15T02:44:19.632409Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print_precision_recall_curves(y_true, y_hat, y_pred, class_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:44:42.445973Z","iopub.execute_input":"2021-11-15T02:44:42.446329Z","iopub.status.idle":"2021-11-15T02:44:43.995969Z","shell.execute_reply.started":"2021-11-15T02:44:42.446297Z","shell.execute_reply":"2021-11-15T02:44:43.994942Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print_auc_curves(y_true, y_hat, y_pred, class_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:44:50.135222Z","iopub.execute_input":"2021-11-15T02:44:50.135897Z","iopub.status.idle":"2021-11-15T02:44:51.429130Z","shell.execute_reply.started":"2021-11-15T02:44:50.135859Z","shell.execute_reply":"2021-11-15T02:44:51.427941Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print_confusion_matrix(y_true, y_hat, y_pred, class_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:44:55.442807Z","iopub.execute_input":"2021-11-15T02:44:55.443159Z","iopub.status.idle":"2021-11-15T02:44:55.465571Z","shell.execute_reply.started":"2021-11-15T02:44:55.443118Z","shell.execute_reply":"2021-11-15T02:44:55.464459Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print_on_vs_all_cmatrix(y_true, y_hat, y_pred, class_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:44:59.280012Z","iopub.execute_input":"2021-11-15T02:44:59.280915Z","iopub.status.idle":"2021-11-15T02:45:00.063366Z","shell.execute_reply.started":"2021-11-15T02:44:59.280877Z","shell.execute_reply":"2021-11-15T02:45:00.062347Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"GradCam","metadata":{}},{"cell_type":"code","source":"model = create_model(5)\nmodel.load_weights('../input/stroke-mobilenet-multi-classification/mobileNet_fold5.h5')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:45:08.905233Z","iopub.execute_input":"2021-11-15T02:45:08.905553Z","iopub.status.idle":"2021-11-15T02:45:10.093582Z","shell.execute_reply.started":"2021-11-15T02:45:08.905517Z","shell.execute_reply":"2021-11-15T02:45:10.092026Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:45:16.339528Z","iopub.execute_input":"2021-11-15T02:45:16.339856Z","iopub.status.idle":"2021-11-15T02:45:16.409747Z","shell.execute_reply.started":"2021-11-15T02:45:16.339808Z","shell.execute_reply":"2021-11-15T02:45:16.408737Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Display\nfrom IPython.display import Image, display\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:45:32.062033Z","iopub.execute_input":"2021-11-15T02:45:32.062390Z","iopub.status.idle":"2021-11-15T02:45:32.068184Z","shell.execute_reply.started":"2021-11-15T02:45:32.062357Z","shell.execute_reply":"2021-11-15T02:45:32.066610Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"model_builder = model\nimg_size = (256, 256)\n# preprocess_input = keras.applications.xception.preprocess_input\ndecode_predictions = keras.applications.mobilenet.decode_predictions\n\nlast_conv_layer_name = \"conv_pw_13_relu\"\n\n# The local path to our target image\n# img_path = '../input/rsna-cq500-abnormal-data/CQ500_Images/CQ500CT1 CQ500CT1/CT 2.55mm_1.2.276.0.7230010.3.1.3.296485376.1.1521714567.2079631/1.2.276.0.7230010.3.1.4.296485376.1.1521714568.2079634.png'\n# display(Image(img_path))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:45:41.391407Z","iopub.execute_input":"2021-11-15T02:45:41.391711Z","iopub.status.idle":"2021-11-15T02:45:41.398524Z","shell.execute_reply.started":"2021-11-15T02:45:41.391678Z","shell.execute_reply":"2021-11-15T02:45:41.397507Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def get_img_array(img_path, size):\n    # `img` is a PIL image of size 299x299\n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    # `array` is a float32 Numpy array of shape (299, 299, 3)\n    array = keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size (1, 299, 299, 3)\n    array = np.expand_dims(array, axis=0)\n    return array\n\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer as well as the output predictions\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # This is the gradient of the output neuron (top predicted or chosen)\n    # with regard to the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:45:43.835795Z","iopub.execute_input":"2021-11-15T02:45:43.836749Z","iopub.status.idle":"2021-11-15T02:45:43.849355Z","shell.execute_reply.started":"2021-11-15T02:45:43.836704Z","shell.execute_reply":"2021-11-15T02:45:43.848023Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"data_generator_test = TrainDataGenerator(val_df,\n                                        class_names, \n                                        VALID_BATCH_SIZE, \n                                        SHAPE,\n                                        augment = False,\n                                        shuffle = False\n                                        )","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:45:52.793807Z","iopub.execute_input":"2021-11-15T02:45:52.794165Z","iopub.status.idle":"2021-11-15T02:45:52.802971Z","shell.execute_reply.started":"2021-11-15T02:45:52.794130Z","shell.execute_reply":"2021-11-15T02:45:52.801865Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def save_and_display_gradcam(img, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n    # Load the original image\n#     img = keras.preprocessing.image.load_img(img_path)\n#     img = keras.preprocessing.image.img_to_array(img)\n\n    # Rescale heatmap to a range 0-255\n    heatmap = np.uint8(255 * heatmap)\n\n    # Use jet colormap to colorize heatmap\n    jet = cm.get_cmap(\"jet\")\n\n    # Use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    # Create an image with RGB colorized heatmap\n    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n\n    # Save the superimposed image\n    superimposed_img.save(cam_path)\n\n    # Display Grad CAM\n    display(Image(cam_path))\n\n\n# save_and_display_gradcam(img_array[0]*255, heatmap)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:45:54.881231Z","iopub.execute_input":"2021-11-15T02:45:54.881535Z","iopub.status.idle":"2021-11-15T02:45:54.890294Z","shell.execute_reply.started":"2021-11-15T02:45:54.881502Z","shell.execute_reply":"2021-11-15T02:45:54.889105Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"!mkdir 0\n!mkdir 1\n!mkdir 2\n!mkdir 3\n!mkdir 4\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:45:59.197585Z","iopub.execute_input":"2021-11-15T02:45:59.197903Z","iopub.status.idle":"2021-11-15T02:46:03.321551Z","shell.execute_reply.started":"2021-11-15T02:45:59.197869Z","shell.execute_reply":"2021-11-15T02:46:03.320148Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"import os\nh=0\nfor i in range(0,10):\n    for j in range (0,64):\n        x = data_generator_test[i][0][j]\n        x = x.reshape(1,256,256,3)\n        np.shape(x)\n        \n        h+=1\n        preds = model.predict(x)\n        heatmap = make_gradcam_heatmap(x*255, model, last_conv_layer_name)\n        p=os.path.join(\"./\", str(np.argmax(preds)))\n        if len(os.listdir(p)) < 21: \n            save_and_display_gradcam(x[0]*255, heatmap, str(np.argmax(preds))+\"/\"+\"cam_\"+str(len(os.listdir(p)))+\".jpg\")\n            print(\"--- \"+str(np.argmax(preds))+\" :  \"+ str(len(os.listdir(p))))\n            ","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:46:08.106416Z","iopub.execute_input":"2021-11-15T02:46:08.107412Z","iopub.status.idle":"2021-11-15T02:49:45.365469Z","shell.execute_reply.started":"2021-11-15T02:46:08.107371Z","shell.execute_reply":"2021-11-15T02:49:45.364316Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nw = 256\nh = 256\nfig = plt.figure(figsize=(9, 13))\ncolumns = 4\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\np=os.path.join(\"./\",\"0\",)\nfor i in range(columns*rows):\n\n#     img = np.random.randint(10, size=(h,w))\n    img = cv2.imread(p+'/'+'cam_'+str(i)+'.jpg')\n\n    \n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(\"prediction : 0\")  # set title\n    plt.imshow(img, )\n\n# do extra plots on selected axes/subplots\n# note: index starts with 0\nax[2].plot(xs, 3*ys)\nax[19].plot(ys**2, xs)\n\nplt.show()  # finally, render the plot","metadata":{"execution":{"iopub.status.busy":"2021-11-15T03:07:35.054471Z","iopub.execute_input":"2021-11-15T03:07:35.054793Z","iopub.status.idle":"2021-11-15T03:07:37.976315Z","shell.execute_reply.started":"2021-11-15T03:07:35.054761Z","shell.execute_reply":"2021-11-15T03:07:37.975402Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nw = 256\nh = 256\nfig = plt.figure(figsize=(9, 13))\ncolumns = 4\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\np=os.path.join(\"./\",\"1\",)\nfor i in range(columns*rows):\n\n#     img = np.random.randint(10, size=(h,w))\n    img = cv2.imread(p+'/'+'cam_'+str(i)+'.jpg')\n\n    \n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(\"prediction : 1\")  # set title\n    plt.imshow(img, )\n\n# do extra plots on selected axes/subplots\n# note: index starts with 0\nax[2].plot(xs, 3*ys)\nax[19].plot(ys**2, xs)\n\nplt.show()  # finally, render the plot","metadata":{"execution":{"iopub.status.busy":"2021-11-15T03:07:42.802218Z","iopub.execute_input":"2021-11-15T03:07:42.802578Z","iopub.status.idle":"2021-11-15T03:07:43.335552Z","shell.execute_reply.started":"2021-11-15T03:07:42.802520Z","shell.execute_reply":"2021-11-15T03:07:43.334003Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nw = 256\nh = 256\nfig = plt.figure(figsize=(9, 13))\ncolumns = 4\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\np=os.path.join(\"./\",\"2\",)\nfor i in range(columns*rows):\n\n#     img = np.random.randint(10, size=(h,w))\n    img = cv2.imread(p+'/'+'cam_'+str(i)+'.jpg')\n\n    \n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(\"prediction : 2\")  # set title\n    plt.imshow(img, )\n\n# do extra plots on selected axes/subplots\n# note: index starts with 0\nax[2].plot(xs, 3*ys)\nax[19].plot(ys**2, xs)\n\nplt.show()  # finally, render the plot","metadata":{"execution":{"iopub.status.busy":"2021-11-15T03:07:49.567640Z","iopub.execute_input":"2021-11-15T03:07:49.567974Z","iopub.status.idle":"2021-11-15T03:07:52.158741Z","shell.execute_reply.started":"2021-11-15T03:07:49.567911Z","shell.execute_reply":"2021-11-15T03:07:52.157945Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nw = 256\nh = 256\nfig = plt.figure(figsize=(9, 13))\ncolumns = 4\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\np=os.path.join(\"./\",\"3\",)\nfor i in range(columns*rows):\n\n#     img = np.random.randint(10, size=(h,w))\n    img = cv2.imread(p+'/'+'cam_'+str(i)+'.jpg')\n\n    \n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(\"prediction : 3\")  # set title\n    plt.imshow(img, )\n\n# do extra plots on selected axes/subplots\n# note: index starts with 0\nax[2].plot(xs, 3*ys)\nax[19].plot(ys**2, xs)\n\nplt.show()  # finally, render the plot","metadata":{"execution":{"iopub.status.busy":"2021-11-15T03:08:19.418900Z","iopub.execute_input":"2021-11-15T03:08:19.419426Z","iopub.status.idle":"2021-11-15T03:08:20.330902Z","shell.execute_reply.started":"2021-11-15T03:08:19.419389Z","shell.execute_reply":"2021-11-15T03:08:20.329169Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nw = 256\nh = 256\nfig = plt.figure(figsize=(9, 13))\ncolumns = 4\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\np=os.path.join(\"./\",\"4\",)\nfor i in range(columns*rows):\n\n#     img = np.random.randint(10, size=(h,w))\n    img = cv2.imread(p+'/'+'cam_'+str(i)+'.jpg')\n\n    \n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(\"prediction : 4\")  # set title\n    plt.imshow(img, )\n\n# do extra plots on selected axes/subplots\n# note: index starts with 0\nax[2].plot(xs, 3*ys)\nax[19].plot(ys**2, xs)\n\nplt.show()  # finally, render the plot","metadata":{"execution":{"iopub.status.busy":"2021-11-15T03:09:05.617595Z","iopub.execute_input":"2021-11-15T03:09:05.617898Z","iopub.status.idle":"2021-11-15T03:09:06.951558Z","shell.execute_reply.started":"2021-11-15T03:09:05.617865Z","shell.execute_reply":"2021-11-15T03:09:06.950141Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}